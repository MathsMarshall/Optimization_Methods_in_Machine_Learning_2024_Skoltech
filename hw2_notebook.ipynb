{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QucZcYA5iP-T"
      },
      "source": [
        "# Optimization Methods in Machine Learning\n",
        "\n",
        "## Homework Assignment 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2898zmkeiP-X"
      },
      "source": [
        "For code-writing part of homework, please submit the single Jupyter Notebook file, where only Python and Markdown/LaTeX are used. The submission should be in the following format: YourName_HW2.ipynb.\n",
        "\n",
        "You are free to modify the function templates and use additional libraries. However, do not use built-in functions if the assignment requires you to implement the method from scratch. Do not forget to add necessary explanations and comments.\n",
        "\n",
        "\n",
        "The works will be checked for plagiarism. The score will be divided by the number of similar works."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yv2W2nmFiP-Y"
      },
      "source": [
        "### Problem 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fP3-BiXEiP-Y"
      },
      "source": [
        "### 1.1 (3 pts)\n",
        "Consider a quadratic convex function\n",
        "$$f(x) = \\frac{1}{2}x^TAx + b^Tx$$\n",
        "\n",
        "where $A\\in\\mathbb{R}^{n \\times n}$ is a positive semidefinite matrix, $x\\in\\mathbb{R}^{n}$,  $b\\in\\mathbb{R}^{n}$.\n",
        "\n",
        "Your task is to find the minimum $x^*$ by implementing gradient descent algorithm. (1 pts)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T6Nf8iMZiP-Y"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WX0Z5C1fiP-Z"
      },
      "outputs": [],
      "source": [
        "def cost(A, x, b):\n",
        "    \"\"\"\n",
        "    Returns:\n",
        "    f: the scalar value of the function at point x\n",
        "    \"\"\"\n",
        "    pass\n",
        "\n",
        "\n",
        "def grad(A, x, b):\n",
        "    \"\"\"\n",
        "    Returns:\n",
        "        nabla_f: The gradient of the quadratic function at point x\n",
        "    \"\"\"\n",
        "    pass\n",
        "\n",
        "\n",
        "def gradient_descent(f, nabla_f, x_0, gamma_k,\n",
        "                     K = 1000, eps = 1e-5):\n",
        "    '''\n",
        "    Parametrs:\n",
        "        f: target function\n",
        "        nabla_f: gradient of the target function\n",
        "        x_0: start point\n",
        "        gamma_k: function for calculating the method step\n",
        "        K: number of iterations (by default 1e3)\n",
        "        eps: accuracy (by default 1e-5)\n",
        "\n",
        "        Returns:\n",
        "            x_opt: the point at which the minimum is reached\n",
        "            err: error vector, err = [convergence_criterion(x_1), \\dots, convergence_criterion(x_K)]\n",
        "    '''\n",
        "    pass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1-Dc3-DciP-Z"
      },
      "source": [
        "Generate $A \\in \\mathbb{R}^{n \\times n}$ and $b \\in \\mathbb{R}^n$ such that $A = A^\\top > 0$ in any way you like and execute the implemented algorithm. You have the flexibility to choose your starting point and convergence criterion. Create a plot showing the values of the convergence criterion against the iteration number for the gradient descent algorithm.\n",
        " (1 point)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "okO1wXyViP-Z"
      },
      "outputs": [],
      "source": [
        "#your code"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iMndjJPJiP-a"
      },
      "source": [
        "Tune a step of the method, try to make the convergence faster. Add to the previous plot the convergence of the tuned method. Make conclusions and comment on the results. (1 pts)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yfLQLXOQiP-a"
      },
      "outputs": [],
      "source": [
        "#your code"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u0IYSiBOiP-a"
      },
      "source": [
        "### 1.2 (5 pts)\n",
        "Your task is to implement a linear regression model using the gradient descent optimizer. We'll use the California Housing dataset from sklearn."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FgqKXWmriP-b"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import fetch_california_housing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import  mean_squared_error\n",
        "\n",
        "# Load the dataset\n",
        "housing = fetch_california_housing()\n",
        "X, y = housing.data, housing.target\n",
        "\n",
        "#Split the data into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2M8rwQtQiP-b"
      },
      "source": [
        "Formulate the loss function for the model (0.5 pts):"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bnx10N7biP-b"
      },
      "source": [
        "\n",
        "$$\n",
        "L = \\dots\n",
        "$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wVQ2_Uh9iP-c"
      },
      "source": [
        "Implement a function for a linear regression model using gradient descent optimization, based on your implementation problem 1.1. (1 pts)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pM-jfhkniP-c"
      },
      "outputs": [],
      "source": [
        "def linear_regression(X, y, learning_rate=0.01, num_iterations=1000):\n",
        "    \"\"\"\n",
        "    Parametrs:\n",
        "    X: numpy array of shape (m, n), where m is the number of samples and n is the number of features\n",
        "    y: numpy array of shape (m,), the target values\n",
        "    learning_rate: float, the learning rate for gradient descent (1e-2 by defolt)\n",
        "    num_iterations: int, number of iterations to perform (1000 by defolt)\n",
        "\n",
        "    Returns:\n",
        "    weights: numpy array of shape (n,), the learned weights.\n",
        "    loss: list of floats, the cost function value at each iteration.\n",
        "    \"\"\"\n",
        "\n",
        "    pass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6UdRLaWpiP-c"
      },
      "source": [
        "Train your model using the training dataset, and evaluate its performance on the test set using Mean Squared Error (MSE) metric. Plot the cost function over iterations to examine convergence. (1 pts)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "me5rYNNTiP-d"
      },
      "outputs": [],
      "source": [
        "#your code"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SzycovHCiP-d"
      },
      "source": [
        "Use scikit-learn’s Linear Regression model to fit the same training data. Compare the coefficients learned by your gradient descent implementation with those learned by scikit-learn’s model. Discuss any discrepancies. Compare the final evaluation metric (MSE) of your model against the scikit-learn model. (1 pts)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0f5vCQ-liP-d"
      },
      "outputs": [],
      "source": [
        "#your code"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nxX6mnCpiP-d"
      },
      "source": [
        "Discuss how the choice of learning rate and number of iterations impacts the convergence and accuracy of the model.\n",
        "Analyze the importance of feature scaling in the performance of gradient descent. (1.5 pts)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JkgEMeQ_iP-e"
      },
      "outputs": [],
      "source": [
        "#your answer"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}